{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Q_Q4tmOnn4F"
   },
   "source": [
    "Author: Quim Serra Faber\n",
    "\n",
    "Date: December 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Q_Q4tmOnn4F"
   },
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCXl9ZVgDv83"
   },
   "source": [
    "In this project, the focus is on using neighbourhood statistics as predictors of alcohol and tobacco consumption. The data sets are:\n",
    "\n",
    "- [Wijk en Buurtstatistieken](https://www.cbs.nl/nl-nl/reeksen/kerncijfers-wijken-en-buurten-2004-2020)\n",
    "\n",
    "- [Rokers per wijk](https://www.volksgezondheidenzorg.info/onderwerp/roken/regionaal-internationaal/regionaal#node-rokers-wijk)\n",
    "\n",
    "- [Alcoholgebruik volgens richtlijn per wijk](https://www.volksgezondheidenzorg.info/onderwerp/alcoholgebruik/regionaal-internationaal/regionaal#node-alcoholgebruik-volgens-richtlijn-ggd-regio)\n",
    "\n",
    "\n",
    "All of the used datasets are from 2016, since it is the most recent year in which all the datasets are available.\n",
    "\n",
    "The latest two datasets have the same structure. The first one is more detailed, and for example has information not only for each \"wijk\" but also for every \"buurt\" inside of each \"wijk\". This more detailed data is not present in the other two datasets, so it will have to be ignored. All the comparisons will be done with respect to the \"wijks\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZI9Zs6yDrqV"
   },
   "source": [
    "# 2 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KLoW3xh5UHy"
   },
   "source": [
    "## 2.1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "yisTwU_7nn4F",
    "outputId": "99bef5a1-11b2-43b1-9dc0-1cf89f4f3bdc"
   },
   "outputs": [],
   "source": [
    "# Load capabilities\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Immediately show plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the data into a pandas data frame, in all cases use a multiindex with \"gemeente\" and \"wijk\"\n",
    "dneigh = pd.read_excel('kwb-2016.xls', index_col= [3,2], decimal=\",\")\n",
    "dsmoke = pd.read_csv('smap2016vzinfo_roker.csv', index_col=[1,2], sep=';', decimal=\",\")\n",
    "ddrink = pd.read_csv('smap2016vzinfo_richtlijn_alcohol.csv', index_col=[1,2], sep=';', decimal=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYxReTht5hZ4"
   },
   "source": [
    "## 2.2 Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EDIeAveYVIYf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 16194 entries, ('Nederland', 'Nederland') to ('Menterwolde', 'Verspreide huizen Muntendam')\n",
      "Columns: 110 entries, gwb_code_10 to g_gewsek\n",
      "dtypes: int64(40), object(70)\n",
      "memory usage: 13.8+ MB\n",
      "Data description:\n",
      "         gwb_code_8         a_inw         a_man       a_vrouw       a_00_14  \\\n",
      "count  1.619400e+04  1.619400e+04  1.619400e+04  1.619400e+04  1.619400e+04   \n",
      "mean   5.878220e+06  4.192644e+03  2.077820e+03  2.113573e+03  6.914600e+02   \n",
      "std    6.198315e+06  1.340222e+05  6.643739e+04  6.758498e+04  2.209844e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    7.003012e+05  2.300000e+02  1.200000e+02  1.100000e+02  3.000000e+01   \n",
      "50%    3.639202e+06  9.650000e+02  4.800000e+02  4.800000e+02  1.450000e+02   \n",
      "75%    8.281277e+06  2.570000e+03  1.275000e+03  1.295000e+03  4.200000e+02   \n",
      "max    1.987031e+07  1.697912e+07  8.417135e+06  8.561985e+06  2.799772e+06   \n",
      "\n",
      "            a_15_24       a_25_44       a_45_64       a_65_oo       a_ongeh  \\\n",
      "count  1.619400e+04  1.619400e+04  1.619400e+04  1.619400e+04  1.619400e+04   \n",
      "mean   5.148293e+02  1.041726e+03  1.183469e+03  7.620098e+02  2.003567e+03   \n",
      "std    1.646951e+04  3.336553e+04  3.779517e+04  2.432159e+04  6.414022e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.500000e+01  4.000000e+01  7.500000e+01  4.000000e+01  9.500000e+01   \n",
      "50%    1.100000e+02  2.100000e+02  2.800000e+02  1.600000e+02  4.250000e+02   \n",
      "75%    3.050000e+02  6.300000e+02  7.350000e+02  4.650000e+02  1.220000e+03   \n",
      "max    2.084673e+06  4.217738e+06  4.791629e+06  3.085308e+06  8.112153e+06   \n",
      "\n",
      "       ...         a_pau      a_lftj6j      a_lfto6j       a_bst_b  \\\n",
      "count  ...  1.619400e+04  1.619400e+04  1.619400e+04  1.619400e+04   \n",
      "mean   ...  1.954085e+03  6.374049e+02  1.316682e+03  1.566662e+03   \n",
      "std    ...  6.387842e+04  2.186363e+04  4.205210e+04  5.046533e+04   \n",
      "min    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    ...  1.450000e+02  4.000000e+01  9.500000e+01  1.050000e+02   \n",
      "50%    ...  4.650000e+02  1.300000e+02  3.250000e+02  3.750000e+02   \n",
      "75%    ...  1.163750e+03  3.400000e+02  8.150000e+02  9.500000e+02   \n",
      "max    ...  8.100865e+06  2.765540e+06  5.335325e+06  6.401865e+06   \n",
      "\n",
      "           a_bst_nb         a_bau          a_m2w      a_opp_ha      a_lan_ha  \\\n",
      "count  1.619400e+04  1.619400e+04   16194.000000  1.619400e+04  1.619400e+04   \n",
      "mean   3.874222e+02  2.433259e+02     161.050080  9.458779e+02  8.319101e+02   \n",
      "std    1.344092e+04  8.141531e+03    5140.684866  3.273640e+04  2.653087e+04   \n",
      "min    0.000000e+00  0.000000e+00       0.000000  0.000000e+00  0.000000e+00   \n",
      "25%    3.500000e+01  2.000000e+01      15.000000  3.700000e+01  3.500000e+01   \n",
      "50%    8.500000e+01  5.500000e+01      40.000000  1.065000e+02  1.010000e+02   \n",
      "75%    2.050000e+02  1.350000e+02     100.000000  5.200000e+02  4.900000e+02   \n",
      "max    1.699000e+06  1.032820e+06  652545.000000  4.154302e+06  3.367996e+06   \n",
      "\n",
      "            a_wat_ha  \n",
      "count   16194.000000  \n",
      "mean      113.959923  \n",
      "std      6268.551159  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         2.000000  \n",
      "75%        10.000000  \n",
      "max    786306.000000  \n",
      "\n",
      "[8 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the neighbourhood data by calling some summary functions\n",
    "print(\"Data information:\")\n",
    "dneigh.info()\n",
    "print(\"Data description:\")\n",
    "print(dneigh.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UnDjWj_i5vhC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3351 entries, (\"'s-Gravenhage\", 'Gemeente') to ('Zwolle', 'Wijk 52 Soestweteringlanden')\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          3351 non-null   int64  \n",
      " 1   Rokers (%)  2948 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 90.4+ KB\n",
      "Data description:\n",
      "                id   Rokers (%)\n",
      "count  3351.000000  2948.000000\n",
      "mean    778.064160    20.168250\n",
      "std     610.567152     4.293861\n",
      "min       3.000000     9.000000\n",
      "25%     307.000000    17.000000\n",
      "50%     588.000000    19.000000\n",
      "75%     995.000000    22.000000\n",
      "max    1987.000000    53.000000\n"
     ]
    }
   ],
   "source": [
    "# Inspect the smoking data by calling some summary functions\n",
    "print(\"Data information:\")\n",
    "dsmoke.info()\n",
    "print(\"Data description:\")\n",
    "print(dsmoke.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eVG5R4rH5ypp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3351 entries, (\"'s-Gravenhage\", 'Gemeente') to ('Zwolle', 'Wijk 52 Soestweteringlanden')\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    3351 non-null   int64  \n",
      " 1   Alcoholrichtlijn (%)  2948 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 90.4+ KB\n",
      "Data description:\n",
      "                id  Alcoholrichtlijn (%)\n",
      "count  3351.000000           2948.000000\n",
      "mean    778.064160             39.298847\n",
      "std     610.567152              6.443029\n",
      "min       3.000000             23.000000\n",
      "25%     307.000000             35.000000\n",
      "50%     588.000000             39.000000\n",
      "75%     995.000000             43.000000\n",
      "max    1987.000000             75.000000\n"
     ]
    }
   ],
   "source": [
    "# Inspect the drinking data by calling some summary functions\n",
    "print(\"Data information:\")\n",
    "ddrink.info()\n",
    "print(\"Data description:\")\n",
    "print(ddrink.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdQX1uD9507R"
   },
   "source": [
    "## 2.3 Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMUheDve511w"
   },
   "source": [
    "Now that we have three different dataframes we have to make them cohesive, since the neighbourhood dataframe has a different order of \"wijks\", and many more samples. We start by putting the indexes in the same order:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qm0gScAkiHHe"
   },
   "source": [
    "The first problem to be solved is the difference in number of samples: for that we must eliminate the additional rows of \"buurts\" in the neighbourhood dataframe, and also eliminate rows which do not add additional information such as the \"gemeentes\" in both the smoke and drink dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FjBVyOmpiLJj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2981"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only maintain the rows corresponding to \"Wijks\"\n",
    "dneigh = dneigh[(dneigh['recs'] == 'Wijk')]\n",
    "len(dneigh.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rX-x1byCiO3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961\n"
     ]
    }
   ],
   "source": [
    "# Iteratively remove the empty rows\n",
    "for i in range(len(dsmoke.index)):\n",
    "    try:\n",
    "        if dsmoke.index[i][1] == 'Gemeente':\n",
    "            dsmoke.drop(dsmoke.index[i], inplace=True)\n",
    "    except IndexError:\n",
    "        break  \n",
    "# Note the use of try and except, since when dropping rows the length of the dataframe gets reduced\n",
    "for i in range(len(ddrink.index)):\n",
    "    try:\n",
    "        if ddrink.index[i][1] == 'Gemeente':\n",
    "            ddrink.drop(ddrink.index[i], inplace=True)\n",
    "    except IndexError:\n",
    "        break\n",
    "print(len(dsmoke.index))\n",
    "\n",
    "# Although dropping a row inside a for loop can lead to problems (the row after the dropped row will be skipped), \n",
    "# in this case it is not a problem: due to the nature of the datasets, there are no consecutive 'Gemeente' rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNJGIQTdWL2u"
   },
   "source": [
    "We thus see that there is a difference of 20 rows, and the case is that there are some additional \"wijks\" in the neighbourhood dataframe. Upon inspection, we can see that these additional rows are just full of empty data, so if we delete them we will not miss any information, and the dataframes will be cohesive. In this case, we just compare the indexes, and if they are different we drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "upQp6kVKWWkW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961\n"
     ]
    }
   ],
   "source": [
    "# Two iterations, to make sure that we do not skip any consecutive index\n",
    "for e in range(0,20):\n",
    "    for i in range(len(dneigh.index)):\n",
    "        try:\n",
    "            if dneigh.index[i][1] != ddrink.index[i][1]:\n",
    "                dneigh.drop(dneigh.index[i], inplace=True)\n",
    "                break\n",
    "        except IndexError:\n",
    "            break\n",
    "print(len(dneigh.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-FSSlC0Wo14"
   },
   "source": [
    "The number of rows is the same in all dataframes, so now we can proceed to sort them. The easiest way to do it is alphabetically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uyiigpkzWrmQ"
   },
   "outputs": [],
   "source": [
    "# Sort all dataframes so that the locations are in the same order\n",
    "dneigh = dneigh.sort_index(ascending=True)\n",
    "dsmoke = dsmoke.sort_index(ascending=True)\n",
    "ddrink = ddrink.sort_index(ascending=True)\n",
    "dneigh.drop(dneigh.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDr4G9XeW3rA"
   },
   "source": [
    "Nevertheless, this sorting does not entirely work, because in all dataframes there are some rows with indexes that do not exist in the other dataframes. As a result, at some points of the dataframes the rows are mismatched. \n",
    "This is solved by dropping all the rows with indexes that are missing in other dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pWetYENni33q"
   },
   "outputs": [],
   "source": [
    "# Remove all rows with indexes that exist in dneigh but not in dsmoke\n",
    "for i in dneigh.index: #  Iterate over the indexes of dneigh\n",
    "    try:\n",
    "        dsmoke.loc[i] # Compute the value of dsmoke with the dneigh index\n",
    "    except:\n",
    "        dneigh.drop([i], axis=0, inplace = True) #  In case of error drop that row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_PZFAPHi92V"
   },
   "source": [
    "Proceed with the same procedure for dsmoke (note that it is not necessary to do it again with the ddrink dataframe, since both dataframes share the same rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FKh185K_i9M0"
   },
   "outputs": [],
   "source": [
    "# Remove all rows with indexes that exist in dsmoke but not in dneigh\n",
    "for i in dsmoke.index: #  Iterate over the indexes of dsmoke\n",
    "    try:\n",
    "        dneigh.loc[i] # Compute the value of dneigh with the dsmoke index\n",
    "    except:\n",
    "        dsmoke.drop([i], axis=0, inplace = True) #  In case of error drop that row\n",
    "        ddrink.drop([i], axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKxvxEwqjDKk"
   },
   "source": [
    "Another problem to solve is the fact that both 'Rokers (%)' and 'Alcoholrichtlijn (%)' columns have some missing data. In this case, it is quite pointless to impute new data, since these are the target variables. Therefore, we remove the rows containing this missing data in all dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-ZGqbb0njKzw"
   },
   "outputs": [],
   "source": [
    "# Two iterations, to make sure that we do not skip any consecutive index\n",
    "for e in range(1, 20):\n",
    "    for i in range(len(dsmoke.index)): \n",
    "        try:\n",
    "            if np.isnan(dsmoke['Rokers (%)'][i]): #  Condition that there is NaN\n",
    "                dneigh.drop(dneigh.index[i], inplace=True) #  Drop row\n",
    "                dsmoke.drop(dsmoke.index[i], inplace=True)\n",
    "        except IndexError:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kHQ3IcyYjMXh"
   },
   "outputs": [],
   "source": [
    "# Same algorithm for ddrink\n",
    "for e in range(1, 20):\n",
    "    for i in range(len(ddrink.index)):\n",
    "        try:\n",
    "            if np.isnan(ddrink['Alcoholrichtlijn (%)'][i]):\n",
    "                ddrink.drop(ddrink.index[i], inplace=True)\n",
    "        except IndexError:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA5diWuXjQac"
   },
   "source": [
    "Check that this has worked properly with the following for loop, which compares the indices of dsmoke and dneigh row by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jn6_PNMrjRyY"
   },
   "outputs": [],
   "source": [
    "for i in range(len(dsmoke.index)):\n",
    "    if dsmoke.index[i][1] != dneigh.index[i][1]:\n",
    "        print(dsmoke.index[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgY9qpfwjTRr"
   },
   "source": [
    "No index is printed so the rows of the dataframes are succesfully synchronized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOaUoDfvYNxZ"
   },
   "source": [
    "## 2.4 Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqI4oEYjjWcG"
   },
   "source": [
    "It is necessary to split the data for the Machine Learning models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pdCGjZ4pYPBw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2916, 105) ys.Shape: (2916,)\n",
      "X.shape: (2916, 105) yd.Shape: (2916,)\n"
     ]
    }
   ],
   "source": [
    "# Create target variables and rest of the datset\n",
    "X = dneigh.loc[:, 'a_inw':'g_gewsek']\n",
    "ys = dsmoke['Rokers (%)'].values\n",
    "yd = ddrink['Alcoholrichtlijn (%)'].values\n",
    "\n",
    "# Test if the separation makes sense:\n",
    "print(\"X.shape: {} ys.Shape: {}\".format(X.shape, ys.shape))\n",
    "print(\"X.shape: {} yd.Shape: {}\".format(X.shape, yd.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxCZx-aIYSrH"
   },
   "source": [
    "Some values of X are NaN, or some string, which we are not interested in. First, we convert all points into floats, and in case that they are a string, NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0uDy8EPYYVUl"
   },
   "outputs": [],
   "source": [
    "# Convert all values to floats\n",
    "X = X.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3MzL7NYk5Ib"
   },
   "source": [
    "There are a few columns that are full of NaNs, so we drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PP72QV_FYbvd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2916, 103) ys.Shape: (2916,)\n"
     ]
    }
   ],
   "source": [
    "# Two iterations, to make sure that we do not skip any index\n",
    "for i in range(len(list(X))):\n",
    "    for e in list(X): #  Iterate over columns\n",
    "        if X[e].isna().sum() == len(X.index): #  Check the count of NaNs in the column\n",
    "            X.drop([e], inplace=True, axis = 1) #  Drop the column\n",
    "print(\"X.shape: {} ys.Shape: {}\".format(X.shape, ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAamjoXljkHE"
   },
   "source": [
    "So two columns have been removed.\n",
    "\n",
    "We can also check that the target variables have no NaN variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GO0ADySDjpFU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.isnan(ys)))\n",
    "print(sum(np.isnan(yd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln-fjvqujsEV"
   },
   "source": [
    "Nevertheless, that is not the case for X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YIQyx0WXjvX7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_inw       False\n",
       "a_man       False\n",
       "a_vrouw     False\n",
       "a_00_14     False\n",
       "a_15_24     False\n",
       "            ...  \n",
       "ste_mvs     False\n",
       "ste_oad     False\n",
       "g_wodief     True\n",
       "g_vernoo     True\n",
       "g_gewsek     True\n",
       "Length: 103, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZVR66hLjzfc"
   },
   "source": [
    "In this case, we use a simple imputer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oLG8jmCrj1cT"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean').fit(X)\n",
    "X = imp.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0HkRXJ-j3a8"
   },
   "source": [
    "Now we can finally split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8bx73w7Vj6dD"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, ys_train, ys_test = train_test_split(X, ys, test_size=0.3, random_state=0)\n",
    "X_train, X_test, yd_train, yd_test = train_test_split(X, yd, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30pEZqvclh-D"
   },
   "source": [
    "Finally, the data is not very sparse and the number of features is low in comparison to the number of samples. This means that ensemble methods such as random forests or gradient boosted decision trees will likely perform better than linear models, and therefore scaling is probably not needed.\n",
    "\n",
    "Additionally, all the features are numerical, so there is no need to use one-hot-encoding. This also means that we will use regression models, and the used metric as an indicative of performance will be R^2."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
